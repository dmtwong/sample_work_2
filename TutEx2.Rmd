---
title: "3450 Exercise 2:  Simple Regression and Hypothesis Testing"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Example: Capital Asset Pricing Model

We will use CAPM in this exercise as it is an application of simple linear regression.

Just to brush up on the theory side, 

(r_security_t - rf_t) = BETA_1 + BETA_2 * (r_mkt_t - rf_t) + e_t

where

```
1. r_security_t: return of security at period t 
2. r_mkt_t: market return at period t 
3. rf_t: risk free rate at period t 
4. e_t: error term at period t
5. BETA_2 estimate the sensitivity of a security in comparison of
   the market, and 
6. BETA_1 (Intercept) captures abnormal return if it is statistically
   significant from 0. 
```

## Know your data

Now we are given a csv file **CAPM_dataset_3.csv**. This file consists the average monthly price of the following assets ranging from Nov 2000 to May 2017

```
- IBM (risky security),
- SP500 index (market), and 
- 3 month T-bill (risk free asset). 
```

Now let's load the data and have a look on it's structure:

```{r}
setwd('C:\\Users\\dmtwong\\Desktop')
data_ex2 <- read.csv('CAPM_dataset_3.csv', stringsAsFactors = F)
str(data_ex2)
```

## Data processing 

As you can see, this dataset need to be further processed before starting the analysis:

```
1. Date is read as 'character' type ( result of stringsAsFactors = F ):  
   Convert it to Date-Time class such as 'Date' and 'POSIXlt' type

2. CAPM model use asset return: 
   Transform from price series to returns
```

**So let's transform the dataset one at a time:**

From display of the dataset, 

Format of 'Date' is: **MM/DD/YYYY** and the corresponding conversion specification is **%m/%d/%Y** (capital sensitive). 

```
Note: If date/time stored in different format, you might read the R Documentation of strptime (run ?strptime)
```

```
transform(<dataset>, <column to be transformed = operation 1>, ... )

will assign output of the operation to the column in the dataset
```


```{r}
data_ex2 <- transform(data_ex2, Date = as.Date(Date, "%m/%d/%Y") )
str(data_ex2)
```

**Next** we are going to calculate the returns of IBM and S&P500.

Let's break it into two parts.  

### Part 1: create a return matrix and insert first column using 'Date' from 'data_ex2'

```{r}
# Alternatively you could simply create a character vector c('IBM', 'SPX')
list_name <- sapply( names(data_ex2)[- c(1,4)], function(x){ substr(x, 3, nchar(x))  } )

# equivalent to c('r_IBM', 'r_SPX')
ret_name <- sapply( list_name, function(x){ paste('r_', x, collapse='', sep='')})

# Creating an empty matrix to store return of IBM and SPX.
# it's one row less because there are no lagged price for first observation in this dataset
ret_matrix <- data.frame(matrix(ncol = length(ret_name) + 1 , 
                                nrow = nrow(data_ex2) - 1 ))

# The first column of return matrix will take the Date column in data_ex2 excluding first observation
ret_matrix[,1] <- data_ex2[-1,1] # Date, for other columns
# set column names for ret_matrix (in fact it is a 'data frame' object )
colnames(ret_matrix) <- c('Date', ret_name)

head(ret_matrix,1); tail(ret_matrix,1)
```

### Part 2: Write a function to calculate return
Recap: r_security_t = 100* ( ( p_security_t/p_security_lagt ) - 1 )

```{r}
# Create a function to calculate return
cal_ret <- function(list_name){
  name_tmp <- paste( 'p_', list_name, sep='')
  tmp_vector <- vector('numeric', nrow(ret_matrix))
  for (i in seq_along(ret_matrix[['Date']])){
    tryCatch( {tmp_vector[i] <- ((data_ex2[i+1, name_tmp]/ data_ex2[i, name_tmp])-1)*100 },
              error = function(x) {tmp_vector[i] = NA}
    )
  }
  return(tmp_vector)
}
```


You could try running cal_ret('IBM'); this produces a sequence of numbers without crashing. But this **does not imply** the function is certainly right. **There's a chance that it produces an incorrect result**

To reduce chances of making covert bugs, try to test some cases after writing your own function. For instance, you may want to calculate the first and last monthly return of IBM by hand, then compare it with result generated by cal_ret(). First and last few observations can be displayed using **head** or **tail** function:

```{r}
head(cal_ret('IBM'), 1)
head(data_ex2, 2)

head(cal_ret('IBM'), 1) == ((data_ex2[2,2]/data_ex2[1,2])-1)*100 # first return of IBM
```

Now let's compare the return on May 2017
```{r}
tail(cal_ret('IBM'), 1)
tail(data_ex2, 2)

tail(cal_ret('IBM'), 1) == ((data_ex2[199,2]/data_ex2[198,2])-1)*100 # last return of IBM
```

These test cases are far from comprehensive, and it does not guarantee 'cal_ret' is well written, but we will accept it at this moment

let's use built-in function  'lapply' to apply 'cal_ret' on the two price series and get the corresponding return series,

then create risk free rate 'r_f' in ret_matrix as well.

```{r}
ret_matrix[, -1] <- lapply(list_name, cal_ret)
ret_matrix$r_f <- data_ex2[-1, 'r_f']

str(ret_matrix)
tail(ret_matrix, 3)

```

### Part 3 (Optional) generate excess return

To be specific, CAPM regress 'excess returns on the stock' against 'excess returns on market portfolio/index'

We could perform arithmetic operation on returns and risk free with I() for formula of 'lm' function, 

but we could also generate the excess return in the data frame explicitly

```{r}
ret_matrix$ex_r_IBM <- ret_matrix$r_IBM - ret_matrix$r_f
ret_matrix$ex_r_SPX  <- ret_matrix$r_SPX  - ret_matrix$r_f

str(ret_matrix)
```

### Introduction to R Object class (Not require)

lm and glm are widely used for fitting linear models. Before using them to run regression, it's good to know a bit of object classes in R. Base type of R is C structure, and can be created only by R core team. So you may consider S3, S4, and RC as the three objects system in R. S3 is the most commonly used system, and **lm and glm** are examples of S3 class. **Class** of an object defines behavior of an object. 

An **object** contains data and methods. As an instance of class, calling **a generic function** (such as summary and print) could lead to different behavior because these generic function will look for **methods** that are associated with corresponding classes. 

In current example, ret_matrix is an object of data.frame (not matrix, sorry for misleading). So the behavior of ret_matrix is defined by data.frame. For following generic functions:

```{r}
methods(class=data.frame)
```

if an instance of data frame is called with these functions, then the call would choose the method generic.data.frame (i.e. summary(ret_matrix) will dispatch to summary.data.frame(ret_matrix) ) If the generic function do not have an method specifically for data.frame, it will dispatch to generic.default(object).

This is too much for new user of R, and you **don't necessary need it for this course**. In case you really want to learn more, read the R documentations of object classes. Otherwise reading the documentation of lm and glm should be sufficient for running regressions. 


## Regression

After processing the price data, the data of returns and excess returns are stored in 'ret_matrix'. Recap the CAPM is regression of 'excess returns on the stock' (y)  on 'excess returns on market portfolio/index' (x). So we will fit CAPM using function lm()

```
lm(formula = <y ~ X1 + X2 +... >, data = <data.frame/matrix/list/enviornment...), ..other arguments.. )
```

```{r}
reg_CAPM <- lm(ex_r_IBM ~ ex_r_SPX, data = ret_matrix)
objects(reg_CAPM)
reg_CAPM$coefficients
```
We could retreive all objects of the lm object one by one. But summary() provide a better way to summarizing the linear model fits. 
```{r}
summary(reg_CAPM)
objects( summary(reg_CAPM) )
```

I will illustrate how method dispatch works by changing the class to something else. This is **not a good programming practice**
```{r}
bad_reg_summary <- summary(reg_CAPM)
class(bad_reg_summary) <- 'list'
# data are remain the same but some form of distortion when printing the object
head(bad_reg_summary, 2) 
```

## Hypothesis Testing
We will use the result of CAPM as an application of hypothesis testing. Just to brush up on the theory side, 

(r_security_t - rf_t) = BETA_1 + BETA_2 * (r_mkt_t - rf_t) + e_t

where coefficient estimates of BETA_1 and BETA_2 have following interpretation in the context of CAPM

```
1. The security outperformed the market if BETA_1 (Intercept) is greater than 0, and underperforms if it is smaller 0. 'BETA_1 = 0' is same as 'the security has no abnormal returns'.

2. BETA_2 estimates the sensitivity of security performance to change in market risk. 
```

**If BETA_2 > 1**, the security has higher sensitivity, and it is an **aggressive stock**; increase in return of the security is larger than 1 for every unit increase in return of market portfolio (and vice versa). 

**If 0 < BETA_2 < 1**, the security is less sensitive to market movement and considered as a **defensive asset**; changes in return of security is smaller than 1 for every unit change in return of market portfolio but still in same direction.

**If BETA_2 < 0**, the security is **super defensive asset**. Not common but possible as the asset performance will have an inverse relations to the market portfolio; return of security increase by BETA_2 unit for every unit **decrease** in return of market portfolio.

### Recap: the regression result 

```{r, echo = FALSE}
summary(reg_CAPM)
```

As above shown, the estimation of BETA_1 and BETA_2 for performance of IBM stock price are `r coefficients( summary(reg_CAPM) )[, 1]`

Does it imply IBM has positive abnormal return (BETA_1 > 0)? Is IBM a stock for risk-adverse investor? Should we buy IBM stocks if we expect a stock market boom is coming?

**These coefficient estimates** play an important role for making these decisions **with the help of inference**. Inference and hypothesis testing are needed to make conclusion because **these estimators are random variables**; they will vary from sample to sample. These estimators are **estimate of true parameters (not exactly the true unknown parameters)**. Even changing the sample period (for example: extending the data to earlier periods or exclude) could lead to different coefficient estimates.

```{r}
# exclude first thirty six rows in the data (data starting from 2003-11)
reg_CAPM_alt <- lm(ex_r_IBM ~ ex_r_SPX, data = ret_matrix[-c(1:36),])
summary(reg_CAPM_alt)
```

As shown, beta (and alpha) for same stock are not deterministic. Fortunately, these random variables follow some known probability distribution when certain model assumptions are satisfied. And let's use hypothesis testing to answer following questions:

### Can we describe IBM as an aggressive asset?

We know BETA_2 is slightly larger than 1 from regression result. But since it is a random variable, do we have enough confidence to believe IBM is an aggressive asset, (moving along the market with larger magnitude)?

This is equivalent to testing:

**H0: BETA_2 <= 1 VS H1: BETA_2 > 1**

let's compute the test statistic first
```{r}
tmp_123 <- summary(reg_CAPM)
beta_1 <- tmp_123$coefficients[2,1]
sd_1 <- tmp_123$coefficients[2,2]
t_stat_1 <- ( beta_1 - 1 ) /  sd_1
t_stat_1 ## the test statistic

critical_val_1 <- qt( 1-0.05 , 196)
critical_val_1 

# t_stat_1> critical_val_1 then reject the right tailed test 
t_stat_1 > critical_val_1
```

Suprisingly (Maybe not so surprise) **we cannot reject the null hypothesis** that IBM moves less volatile or exactly along the market. Note that it's not equivalent to saying 'IBM is certainly an defensive stock, not an aggressive stock'; simply we find evidence against the statement of IBM as aggressive stock.

### Does IBM outperform the market? 

We know estimate of BETA_1 is only slightly larger than 0 but again estimate of BETA_1 is a random variable. It's reasonable to test whether return of IBM stock exceed the market performance.  

This is equivalent to testing:

**H0: BETA_1 <= 0 VS H1: BETA_1 > 0**

```{r, echo=FALSE}
round(tmp_123$coefficients,5)
```

As p-value = 0.823 > 0.05 significance level (or even higher, say 0.10), and t-value is smaller than the critical value we computed, **we cannot reject the null hypothesis that 'the true parameter of BETA_1 <= 0'**. Again, it does not mean null hypothesis is right (IBM has no abnormal return or even underperform); simply we don't have enough evidence to support the alternative hypothesis. (On the other hand if BETA_1 is large enough, p-value for same test wiil become smaller. In such case we might reject the null hypothesis and flavor the alternative at certain significance level) 

If you prefer to compute the test statistics explicitly
```{r}
beta_2 <- tmp_123$coefficients[1,1]
sd_2 <- tmp_123$coefficients[1,2]
t_stat_2 <- ( beta_2 - 0 ) /  sd_2
t_stat_2 ## the test statistic

```

Which is same as the value reported under 't value' and smaller than the critical value. 

### Does performance of IBM really related to business cycle??

Suppose I suspect performance of IBM is completely independent of market (neither countercyclical nor procyclical) and you would like to prove me wrong. This is equivalent to testing:

**H0: BETA_2 = 0 VS H1: BETA_2 != 0**

If you prefer to compute the test statistics explicitly

```{r}
beta_3 <- tmp_123$coefficients[2,1]
sd_3 <- tmp_123$coefficients[2,2]
t_stat_3 <- ( beta_3 - 0 ) /  sd_3
t_stat_3 ## the test statistic

# t_stat_1> critical_val_1 then reject the right tailed test 
critical_val_2 <- qt( 1-0.05/2 , 196) # 2 tail test, each side have 0.025
critical_val_2
t_stat_3 > critical_val_2

# Simply use the values reported by t value and Pr(>|t|)
round(tmp_123$coefficients, 6)

```

With such small p-value, you reject my hypothesis (H0) and flavor your statement(H1): **performance of IBM is related to the market**.




 